# ğŸ›’ Universal E-commerce Parser

## ğŸ“Œ Overview

This project is a **universal e-commerce parser** with web interface and AI-powered URL filtering.

**Input:**
- Website URL (e.g. `https://atelierhome-art.com`)

**Output:**
- `catalog.csv` containing product data
- Folder with downloaded product images
- Web interface for easy parsing

The parser:
- Automatically reads `sitemap.xml`
- Uses AI to filter product URLs
- Extracts product data from structured data and meta tags
- Downloads product images
- Exports everything to CSV

Works on **any online store** without manual configuration.

---

## ğŸ¯ Data to Extract per Product

For each product page extract:

1. **Title** (from og:title, meta tags, or HTML)
2. **Description** (from og:description, meta tags)
3. **Price** (from meta tags or HTML parsing)
4. **Currency** (auto-detected)
5. **All product images**

### Image naming format

```
1.webp
1-1.webp
1-2.webp
2.webp
2-1.webp
```

---

## ğŸ§  Core Idea

Multi-level data extraction:

1. **JSON-LD structured data** (Product schema)
2. **Open Graph meta tags** (og:title, og:description, og:image)
3. **HTML content parsing** (fallback for price patterns)
4. **AI-powered URL filtering** (DeepSeek for product page detection)

---

## ğŸ— Architecture

```
URL
 â†“
robots.txt â†’ sitemap.xml
 â†“
List of all URLs
 â†“
AI filtering (DeepSeek)
 â†“
Product URLs only
 â†“
HTML fetch
 â†“
Multi-level data extraction
 â†“
Image download
 â†“
CSV export
```

---

## ğŸ§© Project Structure

```
.
â”œâ”€â”€ main.py
â”œâ”€â”€ config.py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â”‚
â”œâ”€â”€ crawler/
â”‚   â”œâ”€â”€ sitemap.py
â”‚   â”œâ”€â”€ fetcher.py
â”‚   â””â”€â”€ filters.py
â”‚
â”œâ”€â”€ extractor/
â”‚   â”œâ”€â”€ raw_content.py
â”‚   â””â”€â”€ images.py
â”‚
â”œâ”€â”€ ai/
â”‚   â”œâ”€â”€ deepseek_client.py
â”‚   â””â”€â”€ product_parser.py
â”‚
â”œâ”€â”€ storage/
â”‚   â”œâ”€â”€ csv_writer.py
â”‚   â””â”€â”€ image_store.py
â”‚
â””â”€â”€ output/
    â”œâ”€â”€ images/
    â””â”€â”€ catalog.csv
```

---

## âš™ï¸ Tech Stack

- **Python 3.11+**
- **Playwright** (page rendering)
- **BeautifulSoup4**
- **DeepSeek API**
- `requests`, `lxml`, `pandas`

---

## ğŸ”‘ Configuration

Create `config.py`:

```python
DEEPSEEK_API_KEY = "YOUR_API_KEY"
DEEPSEEK_MODEL = "deepseek-chat"
REQUEST_TIMEOUT = 30
MAX_PAGES = 10000
```

---

## ğŸŒ Sitemap Processing

### Behavior

1. Check:
   - `/sitemap.xml`
   - `/sitemap_index.xml`
   - `robots.txt`
2. Parse all sitemap URLs
3. Extract all page links

---

## ğŸŒ Page Fetching

Use **Playwright (Chromium)**.

Requirements:
- Wait for network idle
- Block analytics & ads
- Return full rendered HTML

---

## ğŸ“¦ Raw Content Extraction

From each page collect:
- `<title>`
- all `<h1â€“h3>`
- full visible text
- all `<img src>`
- all `<script type="application/ld+json">`

---

## ğŸ§  AI Product Extraction

Strict JSON response:

```json
{
  "is_product": true,
  "title": "",
  "description": "",
  "price": "",
  "old_price": "",
  "currency": "",
  "confidence": 0.0
}
```

---

## ğŸ–¼ Image Handling

- Filter icons, svg, trackers
- Prefer large images
- Preserve original format

---

## ğŸ“„ CSV Output

Columns:

```csv
id,url,title,description,price,old_price,currency,images
```

---

## ğŸš€ How to Run

### Local Development

```bash
# Install dependencies
pip install -r requirements.txt
playwright install

# Configure API key
cp .env.example .env
# Edit .env with your DeepSeek API key

# Run web interface
python web.py

# Or run CLI parser
python main.py https://example.com
```

Open http://localhost:5000 for web interface.

### Docker Deployment

```bash
# Build and run with Docker Compose
docker-compose up -d

# Or build manually
docker build -t shop-parser .
docker run -p 5000:5000 -v $(pwd)/output:/app/output shop-parser
```

### Production Deployment

1. Set environment variables:
```bash
export DEEPSEEK_API_KEY="your_key_here"
export FLASK_ENV=production
```

2. Use reverse proxy (nginx) for production
3. Set up SSL certificates
4. Configure monitoring and logging

---

## ğŸ“ˆ Future Improvements

- Async processing
- UI dashboard
- Export to CMS
- SaaS deployment

---

## âœ… Goal

A fully universal AI-based e-commerce parser.

Claude Code should implement all modules accordingly.
